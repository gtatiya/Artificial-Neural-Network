{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edbac2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "#from datasets import load_dataset\n",
    "import torch\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a03de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  (92602,)\n"
     ]
    }
   ],
   "source": [
    "# path = r'D:\\cy101\\cy101_Binary\\shake\\ball_basket\\trial-1\\audio.bin'\n",
    "path = r'D:\\cy101\\cy101_Binary\\shake\\medicine_calcium\\trial-1\\audio.bin'\n",
    "\n",
    "bin_file = open(path, 'rb')\n",
    "data = pickle.load(bin_file)\n",
    "bin_file.close()\n",
    "\n",
    "print('data: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "049aa2b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.config.id2label:  {0: 'Speech', 1: 'Male speech, man speaking', 2: 'Female speech, woman speaking', 3: 'Child speech, kid speaking', 4: 'Conversation', 5: 'Narration, monologue', 6: 'Babbling', 7: 'Speech synthesizer', 8: 'Shout', 9: 'Bellow', 10: 'Whoop', 11: 'Yell', 12: 'Battle cry', 13: 'Children shouting', 14: 'Screaming', 15: 'Whispering', 16: 'Laughter', 17: 'Baby laughter', 18: 'Giggle', 19: 'Snicker', 20: 'Belly laugh', 21: 'Chuckle, chortle', 22: 'Crying, sobbing', 23: 'Baby cry, infant cry', 24: 'Whimper', 25: 'Wail, moan', 26: 'Sigh', 27: 'Singing', 28: 'Choir', 29: 'Yodeling', 30: 'Chant', 31: 'Mantra', 32: 'Male singing', 33: 'Female singing', 34: 'Child singing', 35: 'Synthetic singing', 36: 'Rapping', 37: 'Humming', 38: 'Groan', 39: 'Grunt', 40: 'Whistling', 41: 'Breathing', 42: 'Wheeze', 43: 'Snoring', 44: 'Gasp', 45: 'Pant', 46: 'Snort', 47: 'Cough', 48: 'Throat clearing', 49: 'Sneeze', 50: 'Sniff', 51: 'Run', 52: 'Shuffle', 53: 'Walk, footsteps', 54: 'Chewing, mastication', 55: 'Biting', 56: 'Gargling', 57: 'Stomach rumble', 58: 'Burping, eructation', 59: 'Hiccup', 60: 'Fart', 61: 'Hands', 62: 'Finger snapping', 63: 'Clapping', 64: 'Heart sounds, heartbeat', 65: 'Heart murmur', 66: 'Cheering', 67: 'Applause', 68: 'Chatter', 69: 'Crowd', 70: 'Hubbub, speech noise, speech babble', 71: 'Children playing', 72: 'Animal', 73: 'Domestic animals, pets', 74: 'Dog', 75: 'Bark', 76: 'Yip', 77: 'Howl', 78: 'Bow-wow', 79: 'Growling', 80: 'Whimper (dog)', 81: 'Cat', 82: 'Purr', 83: 'Meow', 84: 'Hiss', 85: 'Caterwaul', 86: 'Livestock, farm animals, working animals', 87: 'Horse', 88: 'Clip-clop', 89: 'Neigh, whinny', 90: 'Cattle, bovinae', 91: 'Moo', 92: 'Cowbell', 93: 'Pig', 94: 'Oink', 95: 'Goat', 96: 'Bleat', 97: 'Sheep', 98: 'Fowl', 99: 'Chicken, rooster', 100: 'Cluck', 101: 'Crowing, cock-a-doodle-doo', 102: 'Turkey', 103: 'Gobble', 104: 'Duck', 105: 'Quack', 106: 'Goose', 107: 'Honk', 108: 'Wild animals', 109: 'Roaring cats (lions, tigers)', 110: 'Roar', 111: 'Bird', 112: 'Bird vocalization, bird call, bird song', 113: 'Chirp, tweet', 114: 'Squawk', 115: 'Pigeon, dove', 116: 'Coo', 117: 'Crow', 118: 'Caw', 119: 'Owl', 120: 'Hoot', 121: 'Bird flight, flapping wings', 122: 'Canidae, dogs, wolves', 123: 'Rodents, rats, mice', 124: 'Mouse', 125: 'Patter', 126: 'Insect', 127: 'Cricket', 128: 'Mosquito', 129: 'Fly, housefly', 130: 'Buzz', 131: 'Bee, wasp, etc.', 132: 'Frog', 133: 'Croak', 134: 'Snake', 135: 'Rattle', 136: 'Whale vocalization', 137: 'Music', 138: 'Musical instrument', 139: 'Plucked string instrument', 140: 'Guitar', 141: 'Electric guitar', 142: 'Bass guitar', 143: 'Acoustic guitar', 144: 'Steel guitar, slide guitar', 145: 'Tapping (guitar technique)', 146: 'Strum', 147: 'Banjo', 148: 'Sitar', 149: 'Mandolin', 150: 'Zither', 151: 'Ukulele', 152: 'Keyboard (musical)', 153: 'Piano', 154: 'Electric piano', 155: 'Organ', 156: 'Electronic organ', 157: 'Hammond organ', 158: 'Synthesizer', 159: 'Sampler', 160: 'Harpsichord', 161: 'Percussion', 162: 'Drum kit', 163: 'Drum machine', 164: 'Drum', 165: 'Snare drum', 166: 'Rimshot', 167: 'Drum roll', 168: 'Bass drum', 169: 'Timpani', 170: 'Tabla', 171: 'Cymbal', 172: 'Hi-hat', 173: 'Wood block', 174: 'Tambourine', 175: 'Rattle (instrument)', 176: 'Maraca', 177: 'Gong', 178: 'Tubular bells', 179: 'Mallet percussion', 180: 'Marimba, xylophone', 181: 'Glockenspiel', 182: 'Vibraphone', 183: 'Steelpan', 184: 'Orchestra', 185: 'Brass instrument', 186: 'French horn', 187: 'Trumpet', 188: 'Trombone', 189: 'Bowed string instrument', 190: 'String section', 191: 'Violin, fiddle', 192: 'Pizzicato', 193: 'Cello', 194: 'Double bass', 195: 'Wind instrument, woodwind instrument', 196: 'Flute', 197: 'Saxophone', 198: 'Clarinet', 199: 'Harp', 200: 'Bell', 201: 'Church bell', 202: 'Jingle bell', 203: 'Bicycle bell', 204: 'Tuning fork', 205: 'Chime', 206: 'Wind chime', 207: 'Change ringing (campanology)', 208: 'Harmonica', 209: 'Accordion', 210: 'Bagpipes', 211: 'Didgeridoo', 212: 'Shofar', 213: 'Theremin', 214: 'Singing bowl', 215: 'Scratching (performance technique)', 216: 'Pop music', 217: 'Hip hop music', 218: 'Beatboxing', 219: 'Rock music', 220: 'Heavy metal', 221: 'Punk rock', 222: 'Grunge', 223: 'Progressive rock', 224: 'Rock and roll', 225: 'Psychedelic rock', 226: 'Rhythm and blues', 227: 'Soul music', 228: 'Reggae', 229: 'Country', 230: 'Swing music', 231: 'Bluegrass', 232: 'Funk', 233: 'Folk music', 234: 'Middle Eastern music', 235: 'Jazz', 236: 'Disco', 237: 'Classical music', 238: 'Opera', 239: 'Electronic music', 240: 'House music', 241: 'Techno', 242: 'Dubstep', 243: 'Drum and bass', 244: 'Electronica', 245: 'Electronic dance music', 246: 'Ambient music', 247: 'Trance music', 248: 'Music of Latin America', 249: 'Salsa music', 250: 'Flamenco', 251: 'Blues', 252: 'Music for children', 253: 'New-age music', 254: 'Vocal music', 255: 'A capella', 256: 'Music of Africa', 257: 'Afrobeat', 258: 'Christian music', 259: 'Gospel music', 260: 'Music of Asia', 261: 'Carnatic music', 262: 'Music of Bollywood', 263: 'Ska', 264: 'Traditional music', 265: 'Independent music', 266: 'Song', 267: 'Background music', 268: 'Theme music', 269: 'Jingle (music)', 270: 'Soundtrack music', 271: 'Lullaby', 272: 'Video game music', 273: 'Christmas music', 274: 'Dance music', 275: 'Wedding music', 276: 'Happy music', 277: 'Funny music', 278: 'Sad music', 279: 'Tender music', 280: 'Exciting music', 281: 'Angry music', 282: 'Scary music', 283: 'Wind', 284: 'Rustling leaves', 285: 'Wind noise (microphone)', 286: 'Thunderstorm', 287: 'Thunder', 288: 'Water', 289: 'Rain', 290: 'Raindrop', 291: 'Rain on surface', 292: 'Stream', 293: 'Waterfall', 294: 'Ocean', 295: 'Waves, surf', 296: 'Steam', 297: 'Gurgling', 298: 'Fire', 299: 'Crackle', 300: 'Vehicle', 301: 'Boat, Water vehicle', 302: 'Sailboat, sailing ship', 303: 'Rowboat, canoe, kayak', 304: 'Motorboat, speedboat', 305: 'Ship', 306: 'Motor vehicle (road)', 307: 'Car', 308: 'Vehicle horn, car horn, honking', 309: 'Toot', 310: 'Car alarm', 311: 'Power windows, electric windows', 312: 'Skidding', 313: 'Tire squeal', 314: 'Car passing by', 315: 'Race car, auto racing', 316: 'Truck', 317: 'Air brake', 318: 'Air horn, truck horn', 319: 'Reversing beeps', 320: 'Ice cream truck, ice cream van', 321: 'Bus', 322: 'Emergency vehicle', 323: 'Police car (siren)', 324: 'Ambulance (siren)', 325: 'Fire engine, fire truck (siren)', 326: 'Motorcycle', 327: 'Traffic noise, roadway noise', 328: 'Rail transport', 329: 'Train', 330: 'Train whistle', 331: 'Train horn', 332: 'Railroad car, train wagon', 333: 'Train wheels squealing', 334: 'Subway, metro, underground', 335: 'Aircraft', 336: 'Aircraft engine', 337: 'Jet engine', 338: 'Propeller, airscrew', 339: 'Helicopter', 340: 'Fixed-wing aircraft, airplane', 341: 'Bicycle', 342: 'Skateboard', 343: 'Engine', 344: 'Light engine (high frequency)', 345: \"Dental drill, dentist's drill\", 346: 'Lawn mower', 347: 'Chainsaw', 348: 'Medium engine (mid frequency)', 349: 'Heavy engine (low frequency)', 350: 'Engine knocking', 351: 'Engine starting', 352: 'Idling', 353: 'Accelerating, revving, vroom', 354: 'Door', 355: 'Doorbell', 356: 'Ding-dong', 357: 'Sliding door', 358: 'Slam', 359: 'Knock', 360: 'Tap', 361: 'Squeak', 362: 'Cupboard open or close', 363: 'Drawer open or close', 364: 'Dishes, pots, and pans', 365: 'Cutlery, silverware', 366: 'Chopping (food)', 367: 'Frying (food)', 368: 'Microwave oven', 369: 'Blender', 370: 'Water tap, faucet', 371: 'Sink (filling or washing)', 372: 'Bathtub (filling or washing)', 373: 'Hair dryer', 374: 'Toilet flush', 375: 'Toothbrush', 376: 'Electric toothbrush', 377: 'Vacuum cleaner', 378: 'Zipper (clothing)', 379: 'Keys jangling', 380: 'Coin (dropping)', 381: 'Scissors', 382: 'Electric shaver, electric razor', 383: 'Shuffling cards', 384: 'Typing', 385: 'Typewriter', 386: 'Computer keyboard', 387: 'Writing', 388: 'Alarm', 389: 'Telephone', 390: 'Telephone bell ringing', 391: 'Ringtone', 392: 'Telephone dialing, DTMF', 393: 'Dial tone', 394: 'Busy signal', 395: 'Alarm clock', 396: 'Siren', 397: 'Civil defense siren', 398: 'Buzzer', 399: 'Smoke detector, smoke alarm', 400: 'Fire alarm', 401: 'Foghorn', 402: 'Whistle', 403: 'Steam whistle', 404: 'Mechanisms', 405: 'Ratchet, pawl', 406: 'Clock', 407: 'Tick', 408: 'Tick-tock', 409: 'Gears', 410: 'Pulleys', 411: 'Sewing machine', 412: 'Mechanical fan', 413: 'Air conditioning', 414: 'Cash register', 415: 'Printer', 416: 'Camera', 417: 'Single-lens reflex camera', 418: 'Tools', 419: 'Hammer', 420: 'Jackhammer', 421: 'Sawing', 422: 'Filing (rasp)', 423: 'Sanding', 424: 'Power tool', 425: 'Drill', 426: 'Explosion', 427: 'Gunshot, gunfire', 428: 'Machine gun', 429: 'Fusillade', 430: 'Artillery fire', 431: 'Cap gun', 432: 'Fireworks', 433: 'Firecracker', 434: 'Burst, pop', 435: 'Eruption', 436: 'Boom', 437: 'Wood', 438: 'Chop', 439: 'Splinter', 440: 'Crack', 441: 'Glass', 442: 'Chink, clink', 443: 'Shatter', 444: 'Liquid', 445: 'Splash, splatter', 446: 'Slosh', 447: 'Squish', 448: 'Drip', 449: 'Pour', 450: 'Trickle, dribble', 451: 'Gush', 452: 'Fill (with liquid)', 453: 'Spray', 454: 'Pump (liquid)', 455: 'Stir', 456: 'Boiling', 457: 'Sonar', 458: 'Arrow', 459: 'Whoosh, swoosh, swish', 460: 'Thump, thud', 461: 'Thunk', 462: 'Electronic tuner', 463: 'Effects unit', 464: 'Chorus effect', 465: 'Basketball bounce', 466: 'Bang', 467: 'Slap, smack', 468: 'Whack, thwack', 469: 'Smash, crash', 470: 'Breaking', 471: 'Bouncing', 472: 'Whip', 473: 'Flap', 474: 'Scratch', 475: 'Scrape', 476: 'Rub', 477: 'Roll', 478: 'Crushing', 479: 'Crumpling, crinkling', 480: 'Tearing', 481: 'Beep, bleep', 482: 'Ping', 483: 'Ding', 484: 'Clang', 485: 'Squeal', 486: 'Creak', 487: 'Rustle', 488: 'Whir', 489: 'Clatter', 490: 'Sizzle', 491: 'Clicking', 492: 'Clickety-clack', 493: 'Rumble', 494: 'Plop', 495: 'Jingle, tinkle', 496: 'Hum', 497: 'Zing', 498: 'Boing', 499: 'Crunch', 500: 'Silence', 501: 'Sine wave', 502: 'Harmonic', 503: 'Chirp tone', 504: 'Sound effect', 505: 'Pulse', 506: 'Inside, small room', 507: 'Inside, large room or hall', 508: 'Inside, public space', 509: 'Outside, urban or manmade', 510: 'Outside, rural or natural', 511: 'Reverberation', 512: 'Echo', 513: 'Noise', 514: 'Environmental noise', 515: 'Static', 516: 'Mains hum', 517: 'Distortion', 518: 'Sidetone', 519: 'Cacophony', 520: 'White noise', 521: 'Pink noise', 522: 'Throbbing', 523: 'Vibration', 524: 'Television', 525: 'Radio', 526: 'Field recording'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label:  Coin (dropping)\n",
      "proba:  torch.Size([527])\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "print('model.config.id2label: ', model.config.id2label)\n",
    "\n",
    "sampling_rate = 16000\n",
    "inputs = feature_extractor(data, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits, dim=-1).item()\n",
    "predicted_label = model.config.id2label[predicted_class_ids]\n",
    "print('predicted_label: ', predicted_label)\n",
    "\n",
    "proba = F.softmax(logits, dim=1)[0]\n",
    "print('proba: ', proba.shape)\n",
    "\n",
    "labels_proba = {}\n",
    "for class_id, p in enumerate(proba):\n",
    "    label = model.config.id2label[class_id]\n",
    "    labels_proba[label] = p.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e831902d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Printer': 0.020859986543655396},\n",
       " {'Vehicle': 0.022946903482079506},\n",
       " {'Cash register': 0.026049446314573288},\n",
       " {'Music': 0.02659224532544613},\n",
       " {'Scissors': 0.02832096256315708},\n",
       " {'Rattle': 0.035546962171792984},\n",
       " {'Speech': 0.05043497681617737},\n",
       " {'Inside, small room': 0.05208072066307068},\n",
       " {'Single-lens reflex camera': 0.09221113473176956},\n",
       " {'Coin (dropping)': 0.17451658844947815}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n = 10\n",
    "[{k: v} for k, v in sorted(labels_proba.items(), key=lambda item: item[1])][-top_n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f942e4",
   "metadata": {},
   "source": [
    "# sentence-transformers/paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affd881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c665564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8724fb131c544f62ae06d5f0d30d7be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)31d34/.gitattributes:   0%|          | 0.00/345 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdd89cd728448ed8e14e1abe740dc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd80645e5304aba892f2a210ed8c455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e4a1a31d34/README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8483b021206842e393bdae42b1c4e263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a1a31d34/config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec589c5b38e400f93c653f8ffb7cef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87346a491007470cbbf112097781d0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f27769211dc4ac9b9300e7942cd19ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79c9c516467490b86e61ca5d9b465b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2667bb62db4e7e8a168e11ae651e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3063ab40784652bc977b6168f7f345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)31d34/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06eebeda120d44ac85501fddd56d0752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403224d807e3415cb8c3c5ccb891ad04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1a31d34/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11453559  0.07683486  0.02626469 ... -0.13231887 -0.00558196\n",
      "   0.31623384]\n",
      " [ 0.00646675  0.16544811 -0.03636225 ...  0.18916449  0.20142542\n",
      "   0.24428211]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e6c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9a419fd4af44ed9617bb4eec5fddea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GyanT\\miniconda3\\envs\\py3_10\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\GyanT\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1ac3114d6942e0bfd048feceb4a0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d919ec68baf94830889058fd4cf1d150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1016e13c414e01869cd64ca31c5944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee0ccd1b0344c9ba9b96e0d37abd93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e2c16309b74e15b13f6fb96fe4947e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.1145,  0.0768,  0.0263,  ..., -0.1323, -0.0056,  0.3162],\n",
      "        [ 0.0065,  0.1654, -0.0364,  ...,  0.1892,  0.2014,  0.2443]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, max pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a4b847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sentences:\n",
      "['<s> This is an example sentence</s>', '<s> Each sentence is converted</s>']\n"
     ]
    }
   ],
   "source": [
    "# Convert embeddings back to sentences\n",
    "decoded_sentences = [tokenizer.decode(ids) for ids in encoded_input['input_ids']]\n",
    "\n",
    "print(\"Output sentences:\")\n",
    "print(decoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546eaaf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': Can't extract `str` to `Vec`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m model_output:\n\u001b[1;32m----> 2\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     line = tokenizer.decode(output)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(line)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py3_10\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3509\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m   3507\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[1;32m-> 3509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   3510\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[0;32m   3511\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3512\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3513\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3514\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py3_10\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:546\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    545\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[1;32m--> 546\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    549\u001b[0m     clean_up_tokenization_spaces\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[0;32m    552\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'ids': Can't extract `str` to `Vec`"
     ]
    }
   ],
   "source": [
    "for output in model_output:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "#     line = tokenizer.decode(output)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b80aea7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the decoded sentence from the token IDs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpooler_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoded_sentence)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py3_10\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3509\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m   3507\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[1;32m-> 3509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   3510\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[0;32m   3511\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3512\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3513\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3514\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py3_10\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:546\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    545\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[1;32m--> 546\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    549\u001b[0m     clean_up_tokenization_spaces\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[0;32m    552\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'ids': 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Get the decoded sentence from the token IDs\n",
    "decoded_sentence = tokenizer.decode(model_output['pooler_output'][0])\n",
    "\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a62567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1159,  0.0142, -0.1938,  ..., -0.0496, -0.0042, -0.0378],\n",
       "        [ 0.1686, -0.0109, -0.2608,  ...,  0.0164, -0.0215, -0.0750]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['pooler_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5198f37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sentences:\n",
      "['<s> This is an example sentence</s>', '<s> Each sentence is converted</s>']\n"
     ]
    }
   ],
   "source": [
    "# Convert embeddings back to sentences\n",
    "decoded_sentences = [tokenizer.decode(ids) for ids in encoded_input['input_ids']]\n",
    "\n",
    "print(\"Output sentences:\")\n",
    "print(decoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdf082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec476e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344e70c0058f4aaeafd2a5559cbeefb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentences:\n",
      "['Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a', 'In a galaxy far, far away, the galaxy is a vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast,', 'Today is a beautiful day for the world.\\n\\nThe world is a beautiful place.\\n\\nThe world is a beautiful place.\\n\\nThe world is a beautiful place.\\n\\nThe world is a beautiful place.\\n\\nThe world is']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "\n",
    "# Sentences you want to generate\n",
    "prompts = [\"Once upon a time\", \"In a galaxy far, far away\", \"Today is a beautiful day\"]\n",
    "\n",
    "# Generate new sentences\n",
    "generated_sentences = []\n",
    "for prompt in prompts:\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    generated_sentence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    generated_sentences.append(generated_sentence)\n",
    "\n",
    "print(\"Generated sentences:\")\n",
    "print(generated_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef9c9026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n",
      "1 In a galaxy far, far away, the galaxy is a vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast, vast,\n",
      "2 Today is a beautiful day for the world.\n",
      "\n",
      "The world is a beautiful place.\n",
      "\n",
      "The world is a beautiful place.\n",
      "\n",
      "The world is a beautiful place.\n",
      "\n",
      "The world is a beautiful place.\n",
      "\n",
      "The world is\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(generated_sentences):\n",
    "    print(i, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ea7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dad088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0081768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote work may also improve work-life balance – because employees have more control over their work schedule, it’s easier for them to take care of personal errands in the morning or during lunch hour.\n",
      "Remote work may also increase work-life balance – as employees have more control over their work schedule, it becomes easier for them to take care of personal errands in the morning or during lunch hour.\n",
      "Remote work may also enhance work-life balance – because employees have more control over their work schedule, it’s easier for them to take care of personal errands in the morning or during lunch hour.\n",
      "Remote work may also improve work-life balance – because employees have more control over their work schedule, it is easier for them to run personal errands in the morning or during lunch time.\n",
      "Remote work may also improve work-life balance – because employees have more control over their work schedule, it’s easier for them to take care of personal errands in the morning or during lunchtime hours.\n"
     ]
    }
   ],
   "source": [
    "# input text\n",
    "sentence = \"Remote work may also enhance work-life balance – because employees have more control over their work schedule, it’s easier for them to take care of personal errands in the morning or during lunch hour.\"\n",
    "\n",
    "sentence = \"paraphrase: \" + sentence + \" </s>\"\n",
    "encoding = tokenizer.encode_plus(sentence,padding=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=256,\n",
    "    do_sample=True,\n",
    "    top_k=120,\n",
    "    top_p=0.95,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=5\n",
    ")\n",
    " \n",
    "for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691505d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Performing crushed action on the wood object of the egg category with deformability: rigid, material: wood, transparent: green, size: small, hardness: hard.\n",
      "1 Conducting crush action on Wood object of the category Egg with deformability: rigid, material: wood, transparency: opaque, color: green, size: small, hardness: hard\n",
      "2 Performing crush action on wood object of the Egg category with deformability: rigid material, transparency: opaque, color: green, size: small, hardness: hard.\n",
      "3 Performs crush action on wood of the egg category with deformability: rigid, material: wood, transparency: opaque, color: green, size: small, hardness: hard.\n",
      "4 Ample action on wood object of the Egg category with deformability: rigid, material: wood, transparency: opaque, color: green, size: small, hardness: hard.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\").to('cuda')\n",
    "\n",
    "sentence = \"Performing crush action on wood object of egg category with deformability: rigid, material: wood, transparency: opaque, color: green, size: small, hardness: hard.\"\n",
    "\n",
    "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=256,\n",
    "    do_sample=True,\n",
    "    top_k=120,\n",
    "    top_p=0.95,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=5\n",
    ")\n",
    "\n",
    "for i, output in enumerate(outputs):\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    print(i, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1efc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32baadd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
